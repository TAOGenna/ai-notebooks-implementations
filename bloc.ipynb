{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 8341.1722\n",
      "Epoch 10, Loss: 3911.9449\n",
      "Epoch 20, Loss: 2826.4286\n",
      "Epoch 30, Loss: 2598.5980\n",
      "Epoch 40, Loss: 2550.0374\n",
      "Epoch 50, Loss: 2533.0261\n",
      "Epoch 60, Loss: 2524.9756\n",
      "Epoch 70, Loss: 2520.4426\n",
      "Epoch 80, Loss: 2517.5066\n",
      "Epoch 90, Loss: 2515.3896\n",
      "\n",
      "Sample Cosine Similarities:\n",
      "blue vs red: 0.4979579746723175\n",
      "cat vs dog: 0.7290394902229309\n",
      "big vs small: 0.7445892095565796\n",
      "car vs boat: 0.2670944035053253\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# --- Data Setup ---\n",
    "color = ['blue','red','green','yellow','white']\n",
    "noun  = ['cat','dog','car','boat','house']\n",
    "verb  = ['is','was','seems','looks']\n",
    "adverb = ['quite','absurdly','extremely']\n",
    "adjective = ['slow','fast','big','small']\n",
    "\n",
    "# Generate random sentences\n",
    "num_sentences = 100\n",
    "all_words = color + noun + verb + adverb + adjective + ['.']\n",
    "vocab_size = len(all_words)\n",
    "word_to_idx = {word: idx for idx, word in enumerate(all_words)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "sentences = [\n",
    "    \" \".join([\n",
    "        random.choice(color), random.choice(noun), random.choice(verb),\n",
    "        random.choice(adverb), random.choice(adjective), '.'\n",
    "    ])\n",
    "    for _ in range(num_sentences)\n",
    "]\n",
    "\n",
    "# --- Training Data Preparation ---\n",
    "# Context-Target Word Pairs (simple skip-gram-like setup)\n",
    "training_pairs = []\n",
    "window_size = 1\n",
    "for sentence in sentences:\n",
    "    words = sentence.split()\n",
    "    for center_idx in range(len(words)):\n",
    "        for offset in range(-window_size, window_size + 1):\n",
    "            context_idx = center_idx + offset\n",
    "            if context_idx != center_idx and 0 <= context_idx < len(words):\n",
    "                training_pairs.append((words[center_idx], words[context_idx]))\n",
    "\n",
    "# Convert to indices\n",
    "training_data = [(word_to_idx[w1], word_to_idx[w2]) for w1, w2 in training_pairs]\n",
    "\n",
    "# --- Model Definition ---\n",
    "class WordEmbeddingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(WordEmbeddingModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "    def forward(self, word_idx):\n",
    "        return self.embeddings(word_idx)\n",
    "\n",
    "# Hyperparameters\n",
    "embed_dim = 8  # Size of the embedding vector\n",
    "model = WordEmbeddingModel(vocab_size, embed_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for center, target in training_data:\n",
    "        center_tensor = torch.tensor([center], dtype=torch.long)\n",
    "        target_tensor = torch.tensor([target], dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        center_embed = model(center_tensor)\n",
    "        scores = model.embeddings.weight @ center_embed.T\n",
    "        scores = scores.T  # Transpose to shape [1, vocab_size]\n",
    "        loss = loss_fn(scores.squeeze(1), target_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# --- Cosine Similarity Function ---\n",
    "def cosine_similarity(word1, word2):\n",
    "    idx1, idx2 = word_to_idx[word1], word_to_idx[word2]\n",
    "    embed1 = model.embeddings(torch.tensor(idx1))\n",
    "    embed2 = model.embeddings(torch.tensor(idx2))\n",
    "    cos_sim = nn.functional.cosine_similarity(embed1, embed2, dim=0)\n",
    "    return cos_sim.item()\n",
    "\n",
    "# --- Testing Cosine Similarity ---\n",
    "print(\"\\nSample Cosine Similarities:\")\n",
    "print(\"blue vs red:\", cosine_similarity(\"blue\", \"red\"))\n",
    "print(\"cat vs dog:\", cosine_similarity(\"cat\", \"dog\"))\n",
    "print(\"big vs small:\", cosine_similarity(\"big\", \"small\"))\n",
    "print(\"car vs boat:\", cosine_similarity(\"car\", \"boat\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat vs small: -0.030236084014177322\n"
     ]
    }
   ],
   "source": [
    "print(\"cat vs small:\", cosine_similarity(\"is\", \"white\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
